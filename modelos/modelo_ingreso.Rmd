---
title: "Modelo Ingreso"
author: "Teresa Ortiz"
date: "8/2/2018"
output: html_document
---

Descripción del modelo de ingreso.

### Datos

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, message=FALSE, echo = FALSE}
library(tidyverse)
library(rstan)
enigh_2010 <- read_csv("../datos/enigh_final.csv")
```

Usaremos la ENIGH 2010, con información de `r nrow(enigh_2010)` hogares y 
`r n_distinct(enigh_2010$ubica_geo)`. Notamos que los faltantes se concentran
en unas cuantas variables:


```{r, message=FALSE}
faltantes <- DataExplorer::plot_missing(enigh_2010)
```

Y los podemos dividir en faltantes por lógica de cuestionario:

* cua_coc = 2 -> coc_duer = NA  
* dis_agua %in% 3:6 -> dot_agua = NA  
* excus = 2 -> sanitario_compartido = NA & adm_ag = NA  
* elect = 5 -> focos = NA

Y 2.0% de faltantes restantes, en las siguientes preguntas:

```{r}
faltantes %>% 
  filter(num_missing == 1253)
```

Notamos que los faltantes de la tabla anterior pertenecen a 1253 hogares, 
repartidos en 401 municipios.

```{r}
enigh_faltantes <- enigh_2010 %>% 
  mutate(faltante = is.na(pared) & is.na(techos))
  
enigh_faltantes %>% 
  group_by(ubica_geo) %>% 
  summarise(porcent_faltantes = 100 * sum(faltante) / n()) %>%
  filter(porcent_faltantes > 0) %>% 
  arrange(desc(porcent_faltantes)) %>% 
  top_n(20, porcent_faltantes)
```

### Faltantes MCAR (missing completely at random, o faltante totalmente al azar)?

Una variable es MCAR si la probabilidad de faltar es la misma para todas las 
unidades. Por ejemplo, si todos los encuestados deciden si contestar la pregunta 
de ingresos lanzando un dado y negándose a contestar si observa un 6. En el 
caso MCAR eliminar las observaciones con faltantes no genera un sesgo en la 
inferencia.

```{r}
faltante_fit <- glm((faltante == 0) ~ jefe_sexo + jefe_edad + total_personas + 
    ic_rezedu + n_ocup, data = enigh_faltantes, family = binomial(link = "logit"))

summary(faltante_fit)
```


Por ahora se eliminarán los faltantes, sin embargo, en corridas futuras se 
propone:

1. En el caso de faltantes por lógica de cuestionario se creará un nuevo código.

2. El 2% de faltantes adicionales se eliminará.

### Variables en modelo

Variables a considerar y selección de muestra.

Consideramos un subconjunto de las variables disponibles:

```{r}
enigh_vars <- enigh_2010 %>% 
  select(hogar_id, ubica_geo, jefe_sexo, pisos, dis_agua, excus, drenaje,
    servicio_celular, servicio_internet, automovil, tam_hog, n_ocup, conapo,
    tam_loc, ingcor, maxnved, indigena) %>% 
  na.omit() %>% 
  filter(ingcor > 0)
```

Y seleccionamos la muestra en dos partes:

1. Seleccionamos 500 municipios.

2. Seleccionamos 10,000 hogares dentro de los municipios del paso 1 (perdemos
2 municipios en el proceso y el tamaño de muestra varía a lo largo de los 
municipios.

```{r}
# seleccionar muestra (municipios y hogares)
set.seed(182791)
in_sample_mun_ids <- sample(unique(enigh_vars$ubica_geo), 500)
in_sample_ids <- enigh_vars %>% 
  filter(ubica_geo %in% in_sample_mun_ids) %>% 
  sample_n(10000) %>% 
  pull(hogar_id)
```

```{r, echo=FALSE}
rm(enigh_2010, enigh_faltantes)
```


### Modelo

El modelo a ajustar es:

```{r, message=FALSE, warning=FALSE}
mod_ingreso_pred <- stan_model(file = "./src/ingreso_prediccion.stan")
mod_ingreso_pred
```

El código incluye una sección de *generated quantities* donde:

1) Se estiman los parámetros de los municipios que no entraron en la muestra.

2) Se predice el ingreso en los hogares que tampoco están en muestra. 
muestra, en el modelo final este proceso se lleva a cabo en R.

Para ajustar el modelo, creamos una función que lee la tabla de datos y regresa 
una lista con los datos a usar en el ajuste del modelo.

```{r}
# Recibe: 
# datos_enigh: los datos enigh y un vector con los hogares seleccionados en la muestra 
# de entrenamiento identificados por la varibale hogares_id
# Regresa en forma de lista:
# datos_modelo: lista para usar directamente en Stan, define datos del modelo.
# ind_mun: índice de clave de municipio e índice correspondiente en modelo.
# covs_mun: incluir covariables en efecto de municipio
preparar_datos <- function(datos_enigh, in_sample_ids, covs_mun = TRUE){
  datos_limpios_hogar <- datos_enigh %>%
    mutate(
      jefe_sexo = jefe_sexo,
      pisos = as.numeric(pisos != 1),
      dis_agua = as.numeric(dis_agua == 1),
      excus = as.numeric(excus == 1),
      drenaje = as.numeric(drenaje!=5),
      servicio_celular =  as.numeric(servicio_celular == 1),
      servicio_internet = as.numeric(servicio_internet == 1),
      automovil = as.numeric(automovil == 1),
      tam_hog = log(1+tam_hog),
      n_ocup = log(1+n_ocup),
      max_ed = log(maxnved), 
      max_ed = ifelse(is.na(max_ed), 1, max_ed), 
      in_sample = hogar_id %in% in_sample_ids
      ) %>% 
    arrange(desc(in_sample))
  x_hogar <- model.matrix(~ jefe_sexo + pisos + dis_agua + excus + 
      drenaje + servicio_celular + servicio_internet + automovil + tam_hog +
      n_ocup + max_ed + n_ocup * max_ed + factor(tam_loc) + indigena, 
      data = datos_limpios_hogar)
  x_hogar <- x_hogar[, colnames(x_hogar) != "(Intercept)"]
  datos_mun <- datos_limpios_hogar %>% 
    group_by(ubica_geo) %>% 
    summarise(
      conapo = first(conapo), 
      tam_mun = floor(median(tam_loc)), 
      in_sample_mun = sum(in_sample) > 0
      ) %>%
      ungroup() %>% 
    mutate(
      geo_id = str_c(1 - in_sample_mun, ubica_geo),
      geo_id = as.numeric(factor(geo_id))
      ) %>% 
    arrange(desc(in_sample_mun), geo_id)
  if (covs_mun) {
    x_mun <- model.matrix(~ factor(tam_mun) * factor(conapo), 
    data = datos_mun)
    x_mun <- x_mun[, colnames(x_mun) != "(Intercept)"]
  } else {
    x_mun <- model.matrix(~ -1 + factor(conapo), data = datos_mun)  
  }
  ind_mun <- select(datos_mun, ubica_geo, geo_id, in_sample_mun)
  datos_limpios_hogar <- datos_limpios_hogar %>% 
    left_join(ind_mun, by = "ubica_geo")
  n <- sum(datos_limpios_hogar$in_sample)
  n_mun = sum(datos_mun$in_sample_mun)
  datos_modelo <- list(
    n = n,
    n_mun = n_mun,
    mh = ncol(x_hogar),
    mm = ncol(x_mun),
    ingreso = datos_limpios_hogar$ingcor[1:n],
    x_hogar = x_hogar[1:n, ],
    x_municipio = x_mun[1:n_mun, ],
    municipio = datos_limpios_hogar$geo_id[1:n], 
    N = nrow(datos_limpios_hogar), 
    todos_municipio = datos_limpios_hogar$geo_id,
    x_todos_hogar = x_hogar,
    in_sample_hogar = as.numeric(datos_limpios_hogar$in_sample),
    N_mun = nrow(x_mun), 
    x_todos_municipio = x_mun, 
    in_sample_mun = as.numeric(datos_mun$in_sample_mun)
    )
  return(list(datos_modelo = datos_modelo, ind_mun = ind_mun, 
    datos_hogar = datos_limpios_hogar, 
    log_ingreso = log(datos_limpios_hogar$ingcor + 1)))
}

datos <- preparar_datos(datos_enigh = enigh_vars, in_sample_ids = in_sample_ids, 
  covs_mun = FALSE)

# fit <- sampling(mod_ingreso_pred, data = datos$datos_modelo, chains = 2, 
#   cores = 2, iter = 700, warmup = 400, control=list(max_treedepth=13))
# save(fit, file = "fit.RData")
load("fit.RData")
```

Ahora revisaremos diagnósticos de convergencia y *pp-checks* esto se puede
hacer con el paquete `shinystan`.

```{r, eval = FALSE}
log_ingreso <- log(1 + datos$datos_modelo$ingreso)
shinystan::launch_shinystan(fit)
```

### Diagnósticos de convergencia

Trazas

```{r, fig.height=4}
library(bayesplot)

posterior <- extract(fit, inc_warmup = TRUE, permuted = FALSE)

color_scheme_set("mix-blue-pink")
p <- mcmc_trace(posterior,  pars = c("sigma", "sigma_mun"), n_warmup = 400,
  facet_args = list(nrow = 2, labeller = label_parsed, scales = "free_y"))
p + facet_text(size = 15)
```

```{r, fig.height=4}
library(bayesplot)

posterior <- extract(fit, inc_warmup = FALSE, permuted = FALSE)

p <- mcmc_trace(posterior,  pars = c("sigma", "sigma_mun"), n_warmup = 0,
  facet_args = list(nrow = 2, labeller = label_parsed, scales = "free_y"))
p + facet_text(size = 15)
```

### Diagnósticos tradicionales

### Trazas

```{r}
library(bayesplot)
posterior <- as.array(fit)
mcmc_trace(posterior, pars = c("sigma", "sigma_mun"),
           facet_args = list(nrow = 2))
```


#### $\hat{R}$
$\hat{R}$ es una estadística de reducción potencial de escala, mide el cociente 
de la varianza promedio en las simulaciones de cada cadena respecto a la 
varianza de todas las cadenas juntas. La idea es que si todas la cadenas han
alcanzado un estado de equilibrio, el numerador y denominador serán iguales 
y $\hat{R}$ será uno, de lo contrario será mayor a uno (Gelman et al. 2013, 
Stan Development Team 2018)). 

```{r}
rhats_betas <- rhat(fit, pars = "beta")
mcmc_rhat(rhats_betas) + ggtitle("R-hat betas") + yaxis_text(hjust = 1)
```

```{r}
rhats_alphas <- rhat(fit, par = "alpha")
mcmc_rhat(rhats_alphas) +
  ggtitle("R-hat alphas") + yaxis_text(hjust = 1)
```

```{r}
rhats <- rhat(fit)
mcmc_rhat(rhats) + ggtitle("R-Hat todo")
```


#### Tamaño de muestra efectivo
El tamaño de muestra efectivo es una estimación del número de simulaciones 
independientes de la distribución posterior del estimador de interés. El valor 
$N_{eff}$ de Stan esta basado en la habilidad de las simulaciones en estimar
la media del parámetro, que está relacionado (más no es necesariamente 
equivalente) con estimar otras funciones de los parámetros. Debido a que las
simulaciones en una cadena de Markov no son independientes si autocorrelación, 
el tamaño de muestra efectivo $N_{eff}$ suele ser menor que el tamaño de muestra
total $N$. Por tanto, entre mayor el cociente de $N_eff$ a $N$ mejor.

```{r}
ratios <- neff_ratio(fit, pars = "beta")
mcmc_neff(ratios, size = 2) + ggtitle("N_eff betas") + yaxis_text(hjust = 1)
```

Una convención usual (aunque arbitraria) es preocuparnos solo si$N_{eff} / N$ es 
menor a 0.1.

#### Autocorrelación

Como vimos arriba $N_{eff}/N$ disminuye cuando hay autocorrelación en las 
simulaciones. Otra manera de visualizar esto es haciendo gráficas de 
autocorrelación. La autocorrelación postitva es indeseable pues significa que la
cadena tiende a quedarse en la misma región entre iteraciones, lo ideal en las
siguientes gráficas es ver que cae a cero rápidamente conforme aumenta la 
dustancia. La autocorrelación negativa también es posible y es útil pues indica
convergencia rápida de la media muestral a la media verdadera.

```{r}
mcmc_acf_bar(posterior, pars = "sigma", lags = 10)
mcmc_acf_bar(posterior, pars = "sigma_mun", lags = 10)

```



### No-U-Turn Sampler


Para los diagnósticos de NUTS se utiliza la log-posterior de cada simulación y 
algunos diagnósticos específicos del muestreador.

```{r, fig.width=4, fig.height=4}
lpost <- log_posterior(fit)
head(lpost)

nuts_p <- nuts_params(fit)
head(nuts_p)
```


Las gráficas asociadas a NUTS sirven para analizar las divergencias, sin 
embargo, en este ajuste no tuvimos divergencias.

### Estiamaciones

```{r}
mcmc_areas(posterior, regex_pars = c("alpha"), prob = 0.8) +
  ggtitle("Distribuciones posteriores", "con medianas e intervalos de 80%")
```

### PP-checks

Cuando hablamos de *posterior predictive checks* lo que buscamos es comparar 
los datos observados con datos simulados de la distribución predictiva 
posterior. La idea detras de *pp-checks* es que si el modelo ajusta bien a los
datos entonces debería de poder generar datos que se parezcan a los datos
observados.

La distribución predictiva posterior es la distribución de la variable 
respuesta (\tilde{y}) implícita en el modelo una vez que usamos los datos 
observados $y$ para actualizar nuestra incertidumbre de los parámetros del 
modelo $\theta$:

$$p(\tilde{y}|y)=\int p(\tilde{y}|\theta)p(\theta|y)d\theta$$

En la ecuación de arriba podemos condicionar también a una matriz de covariables
$X$.

Computacionalmente, lo que haremos es que para cada simulación $s=1,...,S$ de 
los parámetros de la distribución posterior $\theta^{(s)}\sim p(\theta|y)$ 
obtenemos un vector $\tilde{y}^{(s)}$ de tamaño $N$ de la distribución 
predictiva posterior usando el modelo ($p(y|\theta)$) y condicionando a los 
parámetros $\theta^(s)$. Como resultado tenemos una matriz de simualciones de 
$\tilde{y}$ de tamaño $S \times N$.


Cuando simulamos de la distribución predictiva posterior podemos usar los mismos
valores de la matriz de covariables $X$ que usamos al ajustar el modelo o 
podemos simular para nuevas observaciones con sus covariables $\tilde{X}$ 
correspondiente. En el primer caso denotamos las replicaciones $y^{rep}$ pues
las podemos considerar replicaciones de la variable respuesta $y$ más que 
predicciones de observaciones futuras ($\tilde{y}$ con covariables $\tilde{X}$).

En la siguiente gráfica la línea obscura es la distribución del log-ingreso
observado en la muestra de 10,000 hogares, y cada una de las líneas claras es
una replicación del log-ingreso simulada de la distribución predictiva posterior
(estimaciones de densidad por kernel).

```{r}
y <- log(1 + datos$datos_modelo$ingreso)
y_rep <- extract(fit, "log_reps")[[1]] 

ppc_dens_overlay(y, y_rep[1:100, ])
```

Podemos ver la misma información en histogramas.

```{r}
ppc_hist(y, y_rep[1:11, ])
```


Además de comparar la distribución podemos comparar estadísticas y comparar
las estadísticas evaluadas en los datos observados con los correspondientes a 
las replicaciones.


```{r}
ppc_stat(y, y_rep, stat = "min")
```
El máximo en los datos no parece congruente con el modelo.

```{r}
ppc_stat(y, y_rep, stat = "max")
```

También podemos graficar intervalos y ver si contienen al verdadero valor, el 
default es construir intervalos del 90%.

```{r}
inds <- sample(1:1000, 20)
ppc_intervals(y[inds], y_rep[, inds])
```



El paquete bayesplot contiene muchas herramientas más para hacer *pp-checks*.

```{r}
available_ppc()
```

## Calibración

The Calibrated Bayesian (CB) approach to statistical inference capitalizes on the strength of Bayesian and frequentist approaches to statistical inference. In the CB approach, inferences under a particular model are Bayesian, but frequentist methods are useful for model development and model checking. 

Comenzamos graficando intervalos para una muestra de 2000 hogares, graficando 
cada grado de marginación en un panel.

```{r, fig.height=4, fig.width = 7.5, cache=TRUE}
log_ingreso_out <- extract(fit, "log_ingreso_out")[[1]]

log_ingreso <- as.data.frame(t(log_ingreso_out)) %>% 
  mutate(hogar_id = 1:ncol(log_ingreso_out )) %>% 
  gather(n_sim, value, contains("V")) %>% 
  mutate(n_sim = parse_number(n_sim)) 

log_ingreso_df <- log_ingreso %>% 
  group_by(hogar_id) %>% 
  summarise(
    media = mean(value),
    mediana = median(value), 
    desv_est = sd(value), 
    q_inf = quantile(value, probs = 0.025), 
    q_sup = quantile(value, probs = 0.975)
  ) %>% 
  ungroup() %>% 
  bind_cols(datos$datos_hogar) %>% 
  mutate(y = datos$log_ingreso)


n_sample <- 2000
plot_sample <- sample_n(log_ingreso_df, size = n_sample) %>% 
  arrange(media) %>% 
  mutate(id = 1:n_sample)

ggplot(plot_sample, aes(x = id, y = media, ymin = q_inf, 
  ymax = q_sup, color = factor(in_sample))) +
  geom_pointrange(alpha = 0.5, size = 0.2) +
  geom_point(aes(y = y), color = "black", size = 0.3, alpha = 0.5) +
  facet_wrap(~conapo, nrow=1) +
  labs(color = "en muestra", x = "hogares", y = "")
```

Y vemos coberturas:

```{r}
log_ingreso_df %>% 
  filter(!in_sample) %>% 
  mutate(
    cubre_90 = y > media - 1.64 * desv_est & 
      y < media + 1.64 * desv_est,
    cubre_95 = y > media - 2 * desv_est & 
      y < media + 2 * desv_est
    ) %>% 
  summarise(
    cobertura_90 = 100 * mean(cubre_90),
    cobertura_95 = 100 * mean(cubre_95)
    )
```

Y podemos ver si las coberturas fallan por ín.


```{r}
log_ingreso_df %>% 
  filter(!in_sample) %>% 
  group_by(conapo) %>% 
  mutate(
    cubre_90 = y > media - 1.64 * desv_est & 
      y < media + 1.64 * desv_est,
    cubre_95 = y > media - 2 * desv_est & 
      y < media + 2 * desv_est
    ) %>% 
  summarise(
    cobertura_90 = 100 * mean(cubre_90),
    cobertura_95 = 100 * mean(cubre_95)
    )
```

Ahora veamos las medias municipales. Si consideramos la muestra de ENIGH como la 
población podemos evaluar el modelo analizando si cubrimos el valor 
*poblacional* del ingreso promedio a nivel municipio tanto adentro como afuera 
de la muestra.

```{r, error=TRUE}
log_ingreso_mun <- log_ingreso %>% 
  mutate(ingreso_est = exp(value)) %>% 
  left_join(log_ingreso_df) %>% 
  group_by(ubica_geo, n_sim) %>% 
  summarise(
    n = n(),
    n_muestra = sum(in_sample),
    ing_medio = mean(ingreso_est), 
    ingcor_medio = mean(ingcor), 
    ingcor_mediana = median(ingcor), 
    conapo = first(conapo)
    ) %>% 
  group_by(ubica_geo) %>% 
  summarise(
    media_est = mean(ing_medio), 
    mediana_est = median(ing_medio), 
    sd_est = sd(ing_medio), 
    ingcor_medio = first(ingcor_medio), 
    n_muestra = first(n_muestra), 
    conapo = first(conapo)
  ) %>% 
  mutate(n_muestra_cat = Hmisc::cut2(n_muestra, cuts = c(0, 5, 10, 50, 100, 500)))

ggplot(log_ingreso_mun, aes(x = media_est, y = ingcor_medio, 
  color = n_muestra_cat)) +
  geom_abline() + 
  geom_point(alpha = 0.5)

ggplot(log_ingreso_mun, aes(x = reorder(ubica_geo, media_est), 
  y = media_est, ymin = media_est - sd_est, ymax = media_est + sd_est,
  color = n_muestra_cat)) +
  geom_pointrange(alpha = 0.5, size = 0.2) +
  geom_point(aes(y = ingcor_medio), color = "black", alpha = 0.2, size = 0.5) +
  facet_wrap(~conapo)

```

Coberturas municipales

```{r}
log_ingreso_mun %>% 
  mutate(
    cubre_90 = ingcor_medio > media_est - 1.64 * sd_est & 
      ingcor_medio < media_est + 1.64 * sd_est,
    cubre_95 = ingcor_medio > media_est - 2 * sd_est & 
      ingcor_medio < media_est + 2 * sd_est
    ) %>% 
  summarise(
    cobertura_90 = 100 * mean(cubre_90),
    cobertura_95 = 100 * mean(cubre_95)
    )
```


```{r, include=FALSE, eval=FALSE, error=TRUE}
betas_stats <- as.data.frame(t(betas)) %>% 
  mutate(geo_id = 1:ncol(betas)) %>% 
  gather(n_sim, value, contains("V")) %>% 
  mutate(n_sim = parse_number(n_sim)) %>% 
  group_by(geo_id) %>% 
  summarise(
    media = mean(value),
    mediana = median(value), 
    desv_est = sd(value), 
    q_inf = quantile(value, probs = 0.025), 
    q_sup = quantile(value, probs = 0.975)
  ) %>% 
  left_join(datos$ind_mun)

ggplot(betas_stats, aes(x = reorder(geo_id, media), y = media, 
  ymin = media - desv_est, 
  ymax = media + desv_est, color = in_sample_mun))  +
  geom_pointrange(alpha = 0.5, size = 0.2)


ggplot(betas_stats, aes(x = reorder(geo_id, media), y = media, 
  ymin = q_inf, ymax = q_sup, color = in_sample_mun))  +
  geom_pointrange(alpha = 0.5, size = 0.2)

log_ingreso <- log(1 + datos$datos_modelo$ingreso)
shinystan::launch_shinystan(fit)

rstan::summary(fit, pars = c("beta", "alpha", "beta_0", "sigma", "sigma_mun"))$summary

betas <- extract(fit, "beta_out")[[1]]
betas_stats <- as.data.frame(t(betas)) %>% 
  mutate(geo_id = 1:ncol(betas)) %>% 
  gather(n_sim, value, contains("V")) %>% 
  mutate(n_sim = parse_number(n_sim)) %>% 
  group_by(geo_id) %>% 
  summarise(
    media = mean(value),
    mediana = median(value), 
    desv_est = sd(value), 
    q_inf = quantile(value, probs = 0.025), 
    q_sup = quantile(value, probs = 0.975)
  ) %>% 
  left_join(datos$ind_mun)

ggplot(betas_stats, aes(x = reorder(geo_id, media), y = media, 
  ymin = media - desv_est, 
  ymax = media + desv_est, color = in_sample_mun))  +
  geom_pointrange(alpha = 0.5, size = 0.2)


ggplot(betas_stats, aes(x = reorder(geo_id, media), y = media, 
  ymin = q_inf, ymax = q_sup, color = in_sample_mun))  +
  geom_pointrange(alpha = 0.5, size = 0.2)

log_ingreso <- log(1 + datos$datos_modelo$ingreso)
shinystan::launch_shinystan(fit)


rstan::summary(fit, pars = c("log_reps"))$summary

```



